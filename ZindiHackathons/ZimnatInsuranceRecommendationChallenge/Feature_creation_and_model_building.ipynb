{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is Initial submission for the hackathon \n",
    "https://zindi.africa/competitions/zimnat-insurance-recommendation-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/Train_Individual_product_masked.csv')\n",
    "test_df = pd.read_csv('data/Test.csv')\n",
    "submissions= pd.read_csv('submissions/SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID X PCODE</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F86J5PC X P5DA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F86J5PC X RIBP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID X PCODE  Label\n",
       "0  F86J5PC X P5DA      0\n",
       "1  F86J5PC X RIBP      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>join_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>occupation_category_code</th>\n",
       "      <th>P5DA</th>\n",
       "      <th>RIBP</th>\n",
       "      <th>...</th>\n",
       "      <th>FM3X</th>\n",
       "      <th>K6QO</th>\n",
       "      <th>QBOL</th>\n",
       "      <th>JWFN</th>\n",
       "      <th>JZ9D</th>\n",
       "      <th>J9JW</th>\n",
       "      <th>GHYX</th>\n",
       "      <th>ECY3</th>\n",
       "      <th>total_bought</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4WKQSBB</td>\n",
       "      <td>1/2/2019</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>1987</td>\n",
       "      <td>1X1H</td>\n",
       "      <td>2A7I</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>RVSZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4WKQSBB</td>\n",
       "      <td>1/2/2019</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>1987</td>\n",
       "      <td>1X1H</td>\n",
       "      <td>2A7I</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>K6QO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CP5S02H</td>\n",
       "      <td>1/6/2019</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>1981</td>\n",
       "      <td>UAOD</td>\n",
       "      <td>2A7I</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>RVSZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CP5S02H</td>\n",
       "      <td>1/6/2019</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>1981</td>\n",
       "      <td>UAOD</td>\n",
       "      <td>2A7I</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>K6QO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2YKDILJ</td>\n",
       "      <td>1/6/2013</td>\n",
       "      <td>M</td>\n",
       "      <td>U</td>\n",
       "      <td>1991</td>\n",
       "      <td>748L</td>\n",
       "      <td>QZYX</td>\n",
       "      <td>90QI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>SOP4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID join_date sex marital_status  birth_year branch_code  \\\n",
       "0  4WKQSBB  1/2/2019   F              M        1987        1X1H   \n",
       "1  4WKQSBB  1/2/2019   F              M        1987        1X1H   \n",
       "2  CP5S02H  1/6/2019   F              M        1981        UAOD   \n",
       "3  CP5S02H  1/6/2019   F              M        1981        UAOD   \n",
       "4  2YKDILJ  1/6/2013   M              U        1991        748L   \n",
       "\n",
       "  occupation_code occupation_category_code  P5DA  RIBP  ...  FM3X  K6QO  QBOL  \\\n",
       "0            2A7I                     T4MS     0     0  ...     0     1     0   \n",
       "1            2A7I                     T4MS     0     0  ...     0     0     0   \n",
       "2            2A7I                     T4MS     0     0  ...     0     1     0   \n",
       "3            2A7I                     T4MS     0     0  ...     0     0     0   \n",
       "4            QZYX                     90QI     0     0  ...     0     0     0   \n",
       "\n",
       "   JWFN  JZ9D  J9JW  GHYX  ECY3  total_bought  target  \n",
       "0     0     0     0     0     0             2    RVSZ  \n",
       "1     0     0     0     0     0             2    K6QO  \n",
       "2     0     0     0     0     0             2    RVSZ  \n",
       "3     0     0     0     0     0             2    K6QO  \n",
       "4     0     0     0     0     1             3    SOP4  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>join_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>occupation_category_code</th>\n",
       "      <th>P5DA</th>\n",
       "      <th>RIBP</th>\n",
       "      <th>...</th>\n",
       "      <th>AHXO</th>\n",
       "      <th>BSTQ</th>\n",
       "      <th>FM3X</th>\n",
       "      <th>K6QO</th>\n",
       "      <th>QBOL</th>\n",
       "      <th>JWFN</th>\n",
       "      <th>JZ9D</th>\n",
       "      <th>J9JW</th>\n",
       "      <th>GHYX</th>\n",
       "      <th>ECY3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F86J5PC</td>\n",
       "      <td>1/12/2018</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1984</td>\n",
       "      <td>94KC</td>\n",
       "      <td>DZRV</td>\n",
       "      <td>90QI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H6141K3</td>\n",
       "      <td>1/10/2019</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1996</td>\n",
       "      <td>1X1H</td>\n",
       "      <td>J9SY</td>\n",
       "      <td>90QI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RBAYUXZ</td>\n",
       "      <td>1/1/2020</td>\n",
       "      <td>F</td>\n",
       "      <td>W</td>\n",
       "      <td>1968</td>\n",
       "      <td>UAOD</td>\n",
       "      <td>2A7I</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KCBILBQ</td>\n",
       "      <td>1/2/2019</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1989</td>\n",
       "      <td>94KC</td>\n",
       "      <td>2A7I</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSEC1ZJ</td>\n",
       "      <td>1/2/2020</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>1982</td>\n",
       "      <td>UAOD</td>\n",
       "      <td>0KID</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  join_date sex marital_status  birth_year branch_code  \\\n",
       "0  F86J5PC  1/12/2018   M              M        1984        94KC   \n",
       "1  H6141K3  1/10/2019   M              M        1996        1X1H   \n",
       "2  RBAYUXZ   1/1/2020   F              W        1968        UAOD   \n",
       "3  KCBILBQ   1/2/2019   M              M        1989        94KC   \n",
       "4  LSEC1ZJ   1/2/2020   F              M        1982        UAOD   \n",
       "\n",
       "  occupation_code occupation_category_code  P5DA  RIBP  ...  AHXO  BSTQ  FM3X  \\\n",
       "0            DZRV                     90QI     0     0  ...     0     0     0   \n",
       "1            J9SY                     90QI     0     0  ...     0     0     0   \n",
       "2            2A7I                     T4MS     0     0  ...     0     0     0   \n",
       "3            2A7I                     T4MS     0     0  ...     0     0     0   \n",
       "4            0KID                     T4MS     0     0  ...     0     0     0   \n",
       "\n",
       "   K6QO  QBOL  JWFN  JZ9D  J9JW  GHYX  ECY3  \n",
       "0     0     0     0     0     0     0     0  \n",
       "1     1     0     0     0     0     0     0  \n",
       "2     1     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0  \n",
       "4     0     0     0     1     0     0     0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 29 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   ID                        10000 non-null  object\n",
      " 1   join_date                 9999 non-null   object\n",
      " 2   sex                       10000 non-null  object\n",
      " 3   marital_status            10000 non-null  object\n",
      " 4   birth_year                10000 non-null  int64 \n",
      " 5   branch_code               10000 non-null  object\n",
      " 6   occupation_code           10000 non-null  object\n",
      " 7   occupation_category_code  10000 non-null  object\n",
      " 8   P5DA                      10000 non-null  int64 \n",
      " 9   RIBP                      10000 non-null  int64 \n",
      " 10  8NN1                      10000 non-null  int64 \n",
      " 11  7POT                      10000 non-null  int64 \n",
      " 12  66FJ                      10000 non-null  int64 \n",
      " 13  GYSR                      10000 non-null  int64 \n",
      " 14  SOP4                      10000 non-null  int64 \n",
      " 15  RVSZ                      10000 non-null  int64 \n",
      " 16  PYUQ                      10000 non-null  int64 \n",
      " 17  LJR9                      10000 non-null  int64 \n",
      " 18  N2MW                      10000 non-null  int64 \n",
      " 19  AHXO                      10000 non-null  int64 \n",
      " 20  BSTQ                      10000 non-null  int64 \n",
      " 21  FM3X                      10000 non-null  int64 \n",
      " 22  K6QO                      10000 non-null  int64 \n",
      " 23  QBOL                      10000 non-null  int64 \n",
      " 24  JWFN                      10000 non-null  int64 \n",
      " 25  JZ9D                      10000 non-null  int64 \n",
      " 26  J9JW                      10000 non-null  int64 \n",
      " 27  GHYX                      10000 non-null  int64 \n",
      " 28  ECY3                      10000 non-null  int64 \n",
      "dtypes: int64(22), object(7)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1/5/2018\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.join_date.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29132"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.ID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_df.branch_code.nunique())\n",
    "print(test_df.branch_code.nunique())\n",
    "print(len(set(train_df.branch_code.unique()) - set(test_df.branch_code.unique())))\n",
    "print(len(set(test_df.branch_code.unique()) - set(train_df.branch_code.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233\n",
      "187\n",
      "55\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(train_df.occupation_code.nunique())\n",
    "print(test_df.occupation_code.nunique())\n",
    "print(len(set(train_df.occupation_code.unique()) - set(test_df.occupation_code.unique())))\n",
    "print(len(set(test_df.occupation_code.unique()) - set(train_df.occupation_code.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_df.occupation_category_code.nunique())\n",
    "print(test_df.occupation_category_code.nunique())\n",
    "print(len(set(train_df.occupation_category_code.unique()) - set(test_df.occupation_category_code.unique())))\n",
    "print(len(set(test_df.occupation_category_code.unique()) - set(train_df.occupation_category_code.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(train_df.marital_status.nunique())\n",
    "print(test_df.marital_status.nunique())\n",
    "print(len(set(train_df.marital_status.unique()) - set(test_df.marital_status.unique())))\n",
    "print(len(set(test_df.marital_status.unique()) - set(train_df.marital_status.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_df.ID.unique()).intersection(set(test_df.ID.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list = ['P5DA', 'RIBP', '8NN1', '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9',\n",
    "                'N2MW', 'AHXO', 'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_products_info(df):\n",
    "    user_bought_sum = df[product_list].sum(axis=1)\n",
    "    print(\"Total produts bought by all users \",user_bought_sum.sum())\n",
    "    print(\"Average number of buys \", user_bought_sum.mean())\n",
    "    print(\"Max number of buys \", user_bought_sum.max())\n",
    "    print(\"min number of buys \", user_bought_sum.min())\n",
    "#     print(\"percentage_disitribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total produts bought by all users  95358\n",
      "Average number of buys  1.4371317046704746\n",
      "Max number of buys  13\n",
      "min number of buys  1\n"
     ]
    }
   ],
   "source": [
    "print_products_info(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total produts bought by all users  12853\n",
      "Average number of buys  1.2853\n",
      "Max number of buys  7\n",
      "min number of buys  1\n"
     ]
    }
   ],
   "source": [
    "print_products_info(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['total_bought'] = train_df[product_list].sum(axis=1)\n",
    "test_df['total_bought'] = test_df[product_list].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29132"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.ID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.groupby('ID', as_index=False).sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_df['target']\n",
    "target_df = pd.get_dummies(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_df(train, test):\n",
    "    print(\"Train shape :\", train.shape)\n",
    "    print(\"Test shape :\", test.shape)\n",
    "    df = train.drop('target', axis=1).append(test, ignore_index=True)\n",
    "    df['sex'] = df.sex.apply(lambda x: 1 if x=='F' else 0)\n",
    "    df = pd.concat([df, pd.get_dummies(df.marital_status, prefix='marital_status')], axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df.occupation_category_code, prefix='occupation_category_code')], axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df.branch_code, prefix='branch_code')], axis=1)\n",
    "    df['join_date'] = pd.to_datetime(df.join_date)\n",
    "    df.join_date = df.join_date.fillna(df.join_date.mode()[0])\n",
    "    print(df.join_date.isna().value_counts())\n",
    "    df['join_date_month'] = df.join_date.dt.month\n",
    "    df['join_day_of_the_month'] = df.join_date.dt.day\n",
    "    df['join_year'] = df.join_date.dt.year\n",
    "    df = df.drop(columns=['marital_status', 'occupation_category_code', 'branch_code', 'occupation_code',\n",
    "                          'join_date'], axis=1)\n",
    "    print(\"All data columns list: \", df.columns)\n",
    "    print(\"All data shape :\", df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape : (29132, 31)\n",
      "Test shape : (10000, 30)\n",
      "False    39132\n",
      "Name: join_date, dtype: int64\n",
      "All data columns list:  Index(['ID', 'sex', 'birth_year', 'P5DA', 'RIBP', '8NN1', '7POT', '66FJ',\n",
      "       'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO', 'BSTQ', 'FM3X',\n",
      "       'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3', 'total_bought',\n",
      "       'marital_status_D', 'marital_status_F', 'marital_status_M',\n",
      "       'marital_status_P', 'marital_status_R', 'marital_status_S',\n",
      "       'marital_status_U', 'marital_status_W', 'marital_status_f',\n",
      "       'occupation_category_code_56SI', 'occupation_category_code_90QI',\n",
      "       'occupation_category_code_AHH5', 'occupation_category_code_JD7X',\n",
      "       'occupation_category_code_L44T', 'occupation_category_code_T4MS',\n",
      "       'branch_code_1X1H', 'branch_code_30H5', 'branch_code_49BM',\n",
      "       'branch_code_748L', 'branch_code_94KC', 'branch_code_9F9T',\n",
      "       'branch_code_BOAS', 'branch_code_E5SW', 'branch_code_EU3L',\n",
      "       'branch_code_O4JC', 'branch_code_O67J', 'branch_code_UAOD',\n",
      "       'branch_code_X23B', 'branch_code_XX25', 'branch_code_ZFER',\n",
      "       'join_date_month', 'join_day_of_the_month', 'join_year'],\n",
      "      dtype='object')\n",
      "All data shape : (39132, 58)\n"
     ]
    }
   ],
   "source": [
    "all_data = get_preprocessed_df(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uint8     30\n",
       "int64     27\n",
       "object     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = all_data[:29132]\n",
    "pred_data = all_data[29132:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    29132\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data.ID==train_df.ID).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    10000\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_data.ID==test_df.ID).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    29132\n",
       "Name: join_date_month, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.join_date_month.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_id_pcode(model, group, model_type):\n",
    "    if model_type=='DL':\n",
    "        classes_ser = pd.Series(list(target_df.columns))\n",
    "    else:\n",
    "        classes_ser = pd.Series(model.classes_)\n",
    "    classes_ser.index = group.index\n",
    "    group['ID X PCODE'] = group['ID'] + ' X ' + classes_ser\n",
    "    return group\n",
    "\n",
    "def save_predictions(model, predict_data, file_name_prefix, model_type='ML', round_off=5):\n",
    "    if model_type!='DL':\n",
    "        predictions = model.predict_proba(predict_data.drop('ID', axis=1))\n",
    "    else:\n",
    "        predictions = model.predict_proba(predict_data)\n",
    "    #predictions = np.round(predictions, decimals=round_off)\n",
    "    sub_df = pd.DataFrame({'ID':pred_data['ID'], 'PCODE' :predictions.tolist()})\n",
    "    temp = sub_df.explode('PCODE').reset_index(drop=True)\n",
    "    temp = temp.groupby('ID', as_index=False).apply(lambda x: create_id_pcode(model, x, model_type)\n",
    "                                                   ).rename(columns = {'PCODE':'Label'}\n",
    "                                                           )[['ID X PCODE', 'Label']]\n",
    "    temp['Label'] = temp['Label'].astype(float)\n",
    "    # return temp\n",
    "    temp.to_csv('submissions/' + file_name_prefix + '_submission.csv', index=False, float_format='%.7f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building and submissions!! Yayy!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import  StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X= scaler.fit_transform(train_data.drop('ID', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = scaler.transform(pred_data.drop('ID', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target_df, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 256\n",
    "lr = 0.009\n",
    "adam = optimizers.Adam(lr)\n",
    "leaky_relu_alpha =0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_218 (Dense)            (None, 228)               13224     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_115 (LeakyReLU)  (None, 228)               0         \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 228)               0         \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 114)               26106     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_116 (LeakyReLU)  (None, 114)               0         \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 114)               0         \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, 42)                4830      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_117 (LeakyReLU)  (None, 42)                0         \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 21)                903       \n",
      "=================================================================\n",
      "Total params: 45,063\n",
      "Trainable params: 45,063\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(228, input_dim=57, kernel_initializer='normal'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=leaky_relu_alpha))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(114, kernel_initializer='normal'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=leaky_relu_alpha))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(42, activation='relu', kernel_initializer='normal'))\n",
    "model.add(LeakyReLU(alpha=leaky_relu_alpha))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(21, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam' , metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5,\n",
    "                                        mode='auto', restore_best_weights=True),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=3,\n",
    "                                            min_lr=0.00001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator = KerasClassifier(build_fn=baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49764 samples, validate on 16589 samples\n",
      "Epoch 1/200\n",
      "49764/49764 [==============================] - 1s 25us/step - loss: 0.3879 - accuracy: 0.8761 - val_loss: 0.4151 - val_accuracy: 0.8691\n",
      "Epoch 2/200\n",
      "49764/49764 [==============================] - 1s 25us/step - loss: 0.3887 - accuracy: 0.8765 - val_loss: 0.4151 - val_accuracy: 0.8691\n",
      "Epoch 3/200\n",
      "49764/49764 [==============================] - 1s 25us/step - loss: 0.3881 - accuracy: 0.8756 - val_loss: 0.4151 - val_accuracy: 0.8688\n",
      "Epoch 4/200\n",
      "49764/49764 [==============================] - 1s 25us/step - loss: 0.3884 - accuracy: 0.8765 - val_loss: 0.4151 - val_accuracy: 0.8691\n",
      "Epoch 5/200\n",
      "49764/49764 [==============================] - 1s 24us/step - loss: 0.3890 - accuracy: 0.8752 - val_loss: 0.4151 - val_accuracy: 0.8691\n",
      "Epoch 6/200\n",
      "49764/49764 [==============================] - 1s 25us/step - loss: 0.3888 - accuracy: 0.8761 - val_loss: 0.4150 - val_accuracy: 0.8693\n",
      "Epoch 7/200\n",
      "49764/49764 [==============================] - 1s 25us/step - loss: 0.3880 - accuracy: 0.8753 - val_loss: 0.4150 - val_accuracy: 0.8693\n",
      "Epoch 8/200\n",
      "49764/49764 [==============================] - 1s 25us/step - loss: 0.3881 - accuracy: 0.8762 - val_loss: 0.4150 - val_accuracy: 0.8690\n",
      "Epoch 9/200\n",
      "49764/49764 [==============================] - 1s 28us/step - loss: 0.3887 - accuracy: 0.8747 - val_loss: 0.4150 - val_accuracy: 0.8691\n",
      "Epoch 10/200\n",
      "49764/49764 [==============================] - 1s 26us/step - loss: 0.3875 - accuracy: 0.8768 - val_loss: 0.4149 - val_accuracy: 0.8691\n",
      "Epoch 11/200\n",
      "49764/49764 [==============================] - 1s 25us/step - loss: 0.3890 - accuracy: 0.8764 - val_loss: 0.4149 - val_accuracy: 0.8691\n",
      "Epoch 12/200\n",
      "49764/49764 [==============================] - 1s 26us/step - loss: 0.3882 - accuracy: 0.8762 - val_loss: 0.4149 - val_accuracy: 0.8689\n",
      "Epoch 13/200\n",
      "49764/49764 [==============================] - 1s 27us/step - loss: 0.3892 - accuracy: 0.8749 - val_loss: 0.4148 - val_accuracy: 0.8691\n",
      "Epoch 14/200\n",
      "49764/49764 [==============================] - 1s 29us/step - loss: 0.3880 - accuracy: 0.8756 - val_loss: 0.4149 - val_accuracy: 0.8691\n",
      "Epoch 15/200\n",
      "49764/49764 [==============================] - 1s 27us/step - loss: 0.3886 - accuracy: 0.8757 - val_loss: 0.4148 - val_accuracy: 0.8689\n",
      "Epoch 16/200\n",
      "49764/49764 [==============================] - 1s 26us/step - loss: 0.3875 - accuracy: 0.8762 - val_loss: 0.4149 - val_accuracy: 0.8693\n",
      "Epoch 17/200\n",
      "49764/49764 [==============================] - 1s 27us/step - loss: 0.3892 - accuracy: 0.8754 - val_loss: 0.4148 - val_accuracy: 0.8691\n",
      "Epoch 18/200\n",
      "49764/49764 [==============================] - 1s 26us/step - loss: 0.3892 - accuracy: 0.8758 - val_loss: 0.4148 - val_accuracy: 0.8693\n",
      "Epoch 19/200\n",
      "49764/49764 [==============================] - 1s 27us/step - loss: 0.3879 - accuracy: 0.8759 - val_loss: 0.4149 - val_accuracy: 0.8691\n",
      "Epoch 20/200\n",
      "49764/49764 [==============================] - 1s 26us/step - loss: 0.3892 - accuracy: 0.8763 - val_loss: 0.4147 - val_accuracy: 0.8691\n",
      "Epoch 21/200\n",
      "49764/49764 [==============================] - 1s 27us/step - loss: 0.3881 - accuracy: 0.8760 - val_loss: 0.4147 - val_accuracy: 0.8689\n",
      "Epoch 22/200\n",
      "49764/49764 [==============================] - 1s 29us/step - loss: 0.3863 - accuracy: 0.8765 - val_loss: 0.4148 - val_accuracy: 0.8694\n",
      "Epoch 23/200\n",
      "49764/49764 [==============================] - 1s 28us/step - loss: 0.3885 - accuracy: 0.8759 - val_loss: 0.4147 - val_accuracy: 0.8694\n",
      "Epoch 24/200\n",
      "49764/49764 [==============================] - 1s 26us/step - loss: 0.3880 - accuracy: 0.8755 - val_loss: 0.4147 - val_accuracy: 0.8691\n",
      "Epoch 25/200\n",
      "49764/49764 [==============================] - 1s 25us/step - loss: 0.3872 - accuracy: 0.8767 - val_loss: 0.4148 - val_accuracy: 0.8693\n"
     ]
    }
   ],
   "source": [
    "# results = cross_val_score(estimator, train_data.drop('ID', axis=1), target_df, cv=kfold, verbose=2)\n",
    "# print(\"dl: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "# results\n",
    "model_history = model.fit(X_train, y_train,\n",
    "                          validation_data=(X_test,y_test),\n",
    "                          epochs=200, batch_size=batch, verbose=1,\n",
    "                          callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66353 samples, validate on 16589 samples\n",
      "Epoch 1/20\n",
      "66353/66353 [==============================] - 2s 26us/step - loss: 0.4016 - accuracy: 0.8722 - val_loss: 0.4138 - val_accuracy: 0.8694\n",
      "Epoch 2/20\n",
      "66353/66353 [==============================] - 2s 24us/step - loss: 0.3997 - accuracy: 0.8730 - val_loss: 0.4131 - val_accuracy: 0.8696\n",
      "Epoch 3/20\n",
      "66353/66353 [==============================] - 2s 26us/step - loss: 0.4003 - accuracy: 0.8729 - val_loss: 0.4125 - val_accuracy: 0.8700\n",
      "Epoch 4/20\n",
      "66353/66353 [==============================] - 2s 24us/step - loss: 0.4019 - accuracy: 0.8728 - val_loss: 0.4119 - val_accuracy: 0.8701\n",
      "Epoch 5/20\n",
      "66353/66353 [==============================] - 2s 25us/step - loss: 0.4014 - accuracy: 0.8734 - val_loss: 0.4116 - val_accuracy: 0.8701\n",
      "Epoch 6/20\n",
      "66353/66353 [==============================] - 2s 24us/step - loss: 0.3998 - accuracy: 0.8719 - val_loss: 0.4109 - val_accuracy: 0.8702\n",
      "Epoch 7/20\n",
      "66353/66353 [==============================] - 2s 25us/step - loss: 0.3989 - accuracy: 0.8736 - val_loss: 0.4105 - val_accuracy: 0.8703\n",
      "Epoch 8/20\n",
      "66353/66353 [==============================] - 2s 26us/step - loss: 0.3997 - accuracy: 0.8726 - val_loss: 0.4101 - val_accuracy: 0.8703\n",
      "Epoch 9/20\n",
      "66353/66353 [==============================] - 2s 26us/step - loss: 0.4015 - accuracy: 0.8727 - val_loss: 0.4096 - val_accuracy: 0.8705\n",
      "Epoch 10/20\n",
      "66353/66353 [==============================] - 2s 25us/step - loss: 0.3994 - accuracy: 0.8732 - val_loss: 0.4093 - val_accuracy: 0.8704\n",
      "Epoch 11/20\n",
      "66353/66353 [==============================] - 2s 27us/step - loss: 0.3984 - accuracy: 0.8743 - val_loss: 0.4091 - val_accuracy: 0.8707\n",
      "Epoch 12/20\n",
      "66353/66353 [==============================] - 2s 26us/step - loss: 0.3991 - accuracy: 0.8734 - val_loss: 0.4088 - val_accuracy: 0.8705\n",
      "Epoch 13/20\n",
      "66353/66353 [==============================] - 2s 25us/step - loss: 0.3985 - accuracy: 0.8736 - val_loss: 0.4084 - val_accuracy: 0.8706\n",
      "Epoch 14/20\n",
      "66353/66353 [==============================] - 2s 28us/step - loss: 0.4002 - accuracy: 0.8733 - val_loss: 0.4080 - val_accuracy: 0.8708\n",
      "Epoch 15/20\n",
      "66353/66353 [==============================] - 2s 28us/step - loss: 0.3990 - accuracy: 0.8727 - val_loss: 0.4078 - val_accuracy: 0.8709\n",
      "Epoch 16/20\n",
      "66353/66353 [==============================] - 2s 27us/step - loss: 0.3984 - accuracy: 0.8741 - val_loss: 0.4076 - val_accuracy: 0.8708\n",
      "Epoch 17/20\n",
      "66353/66353 [==============================] - 2s 26us/step - loss: 0.3985 - accuracy: 0.8730 - val_loss: 0.4072 - val_accuracy: 0.8708\n",
      "Epoch 18/20\n",
      "66353/66353 [==============================] - 2s 26us/step - loss: 0.3985 - accuracy: 0.8736 - val_loss: 0.4069 - val_accuracy: 0.8709\n",
      "Epoch 19/20\n",
      "66353/66353 [==============================] - 2s 26us/step - loss: 0.3980 - accuracy: 0.8737 - val_loss: 0.4066 - val_accuracy: 0.8710\n",
      "Epoch 20/20\n",
      "66353/66353 [==============================] - 2s 25us/step - loss: 0.3973 - accuracy: 0.8743 - val_loss: 0.4065 - val_accuracy: 0.8711\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(X, target_df,\n",
    "                          validation_data=(X_test,y_test),\n",
    "                          epochs=20, batch_size=batch, verbose=1,\n",
    "                          callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16589/16589 [==============================] - 1s 70us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40653494059629913, 0.8710591197013855]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.94995825e-05, 8.14760915e-06, 9.89021100e-06, ...,\n",
       "        1.13811046e-04, 3.59683622e-06, 8.96496495e-05],\n",
       "       [2.21499498e-03, 1.11731053e-04, 1.13448899e-04, ...,\n",
       "        1.21669853e-02, 1.68536149e-03, 2.77323904e-03],\n",
       "       [1.79893832e-04, 2.51625152e-05, 2.12652412e-05, ...,\n",
       "        4.84824326e-04, 9.47586086e-05, 1.33988244e-04],\n",
       "       ...,\n",
       "       [3.06474579e-09, 8.39255998e-10, 1.81320875e-10, ...,\n",
       "        1.47882142e-08, 9.99998927e-01, 9.03474795e-10],\n",
       "       [6.37342855e-02, 4.32902901e-03, 1.29848840e-02, ...,\n",
       "        3.42637360e-01, 1.93970263e-01, 6.77727982e-02],\n",
       "       [4.26845436e-05, 1.88561359e-07, 3.22780966e-06, ...,\n",
       "        6.72417373e-05, 9.99832630e-01, 1.47404153e-05]], dtype=float32)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'ID':pred_data['ID'], \n",
    "              'PCODE' : estimator.predict_proba(pred_data.drop('ID', axis=1)).tolist()\n",
    "             }).explode('PCODE').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predictions(model, X_pred, 'dl_Dense-228-114-42-21_Lrelu1_LR009_batch256', model_type='DL')#.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmc = lgbm.LGBMClassifier(num_leaves=10, n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = xgboost.XGBClassifier(num_leaves=10, n_estimators=50, max_depth=21, learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier( max_depth=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "skfold = StratifiedKFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/lavanyamk/venv_dedupe/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   7.5s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=  11.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  12.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  19.4s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   8.8s\n",
      "Baseline: 86.99% (0.28%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   59.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.87073547, 0.87251201, 0.87131091, 0.87068521, 0.86443299])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = cross_val_score(lgbmc, X, target, cv=skfold, verbose=2)#, scoring='neg_log_loss')\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmc.fit(X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_score(xgbc, X, target, cv=skfold, verbose=2, scoring='neg_log_loss')\n",
    "print(\"xgbc: %.2f%% (%.2f%%)\" % (results.mean(), results.std()))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=50, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc.fit(train_data.drop('ID', axis=1), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predictions(lgbmc, pred_data, 'lgbmc_num_leaves_50-n_estimators_400')#.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predictions(xgbc, pred_data, 'xgbc_n_estimators_50')#.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dedupe_kernel",
   "language": "python",
   "name": "dedupe_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
